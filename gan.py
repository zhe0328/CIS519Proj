# -*- coding: utf-8 -*-
"""gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19tSkVE72377XLyIUgLn2I9b_wyeG0n5M
"""

from google.colab import drive
import torch
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import numpy as np
import os, os.path
import copy
import torch.nn.functional as F

# !cat /proc/meminfo
if torch.cuda.is_available():
  print("CUDA available")
  os.environ['CUDA_VISIBLE_DEVICES'] ='0'

prefix = '/content/drive'
drive.mount(prefix, force_remount=True)
working_dir = prefix+'/Shareddrives/CIS519'
images_dir = working_dir+'/RAW_DATA/small_dataset/'
print("Working directory: "+working_dir)
print("Images directory: "+images_dir)

from __future__ import print_function, division

import random
from random import shuffle

import numpy as np
import matplotlib.pyplot as plt
import copy

import os
from os import listdir
from os.path import join

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
import torch.nn.functional as F

import torchvision
import torchvision.utils as vutils
from torchvision import utils, models

import warnings
warnings.filterwarnings("ignore")

np.random.seed(42)
random.seed(10)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.manual_seed(999)
device = torch.device("cuda")
m = nn.Softmax(dim=1)

# Number of workers for dataloader
workers = 2

# Batch size during training
batch_size = 128

# Spatial size of training images. All images will be resized to this
#   size using a transformer.
image_size = 64

# Number of channels in the training images. For color images this is 3
nc = 3

# Size of z latent vector (i.e. size of generator input)
nz = 100

# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64

# Number of training epochs
num_epochs = 50

# Learning rate for optimizers
lr = 0.0002

# Beta1 hyperparam for Adam optimizers
beta1 = 0.5

# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1

TRAIN = 'train'
VAL = 'valid'
TEST = 'test'
LABEL = 'labeled'

# GAN Takes 224x224 images as input, so we resize all of them
data_transforms = {
    TRAIN: transforms.Compose([
        # Data augmentation is a good practice for the train set
        # Here, we randomly crop the image to 64x64 and
        # randomly flip it horizontally. 
        transforms.Resize(image_size),
        transforms.CenterCrop(image_size),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ]),
    VAL: transforms.Compose([
        transforms.Resize(image_size),
        transforms.CenterCrop(image_size),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ]),
    TEST: transforms.Compose([
        transforms.Resize(image_size),
        transforms.CenterCrop(image_size),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ]),
    LABEL: transforms.Compose([
        transforms.Resize(image_size),
        transforms.CenterCrop(image_size),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ])
}

image_datasets = {
    x: datasets.ImageFolder(
        os.path.join(images_dir, x), 
        transform=data_transforms[x]
    )
    for x in [TRAIN, VAL, TEST, LABEL]
}

dataloaders = {
    x: torch.utils.data.DataLoader(
        image_datasets[x], batch_size=batch_size,
        shuffle=True, num_workers=workers        #num_workers=4
    )
    for x in [TRAIN, VAL, TEST, LABEL]
}

dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST, LABEL]}

for x in [TRAIN, VAL, TEST, LABEL]:
    print("Loaded {} images under {}".format(dataset_sizes[x], x))
    
print("Classes: ")
class_names = image_datasets[TRAIN].classes
print(image_datasets[TRAIN].classes)

labeled_data, labeled_classes = next(iter(dataloaders[LABEL]))
labeled_data = labeled_data.to(device)
labeled_classes = labeled_classes.to(device)

def imshow(inp, title=None):
    inp = inp.numpy().transpose((1, 2, 0))
    plt.figure(figsize=(10, 10))
    plt.axis('off')
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)

def show_databatch(inputs, classes):
    out = torchvision.utils.make_grid(inputs)
    imshow(out, title=[class_names[x] for x in classes])

# Get a batch of training data
inputs, classes = next(iter(dataloaders[TRAIN]))
show_databatch(inputs, classes)

# custom weights initialization called on netG and netD
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

# Generator Code
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        # self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d( nz, ngf * 8, 7, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 7 x 7
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 14 x 14
            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 28 x 28
            nn.ConvTranspose2d( ngf * 2, ngf, 4, 4, 0, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 112 x 112
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 224 x 224
        )

    def forward(self, input):
        return self.main(input)
    
# A noise vector to be used for generating images at the end of each training epoch
fixed_noise = torch.randn(64, nz, 1, 1, device=device)

netG = Generator().to(device)
netG.apply(weights_init)
print(netG)

classifier = models.resnet18()
num_ftrs = classifier.fc.in_features
classifier.fc = nn.Linear(num_ftrs, 2)
classifier = classifier.to(device)
optimizerG = optim.Adam(netG.parameters(), lr=0.002, betas= (0.5, 0.999))
optimizerC = optim.Adam(classifier.parameters(), lr=0.002, betas= (0.5, 0.999))#, dampening=0, weight_decay=0.0001)
criterion = nn.CrossEntropyLoss()

def test(model, device, test_loader, m_test, display = False, set_num = 2):
  # set_num: a number from 0, 1, 2, where 0 is train, 1 is valid, 2 is test
    set_labels = ['train', 'validation', 'test']
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for batch_number, (images, labels) in enumerate(test_loader):
            data = images.type('torch.FloatTensor').to(device)
            labels = labels.to(device)
            target = labels.type(dtype=torch.long).squeeze().to(device)
            output = model(data).to(device)
            prob = m(output)
            test_loss += criterion(prob, target).item()
            # test_loss += criterion(prob_label, target).item() 
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= m_test

    if display == True:
        print('\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        set_labels[set_num], test_loss, correct, m_test,
        100. * correct / m_test))
           
    return test_loss, 100. * correct / m_test

train_loss, train_accuracy = test(classifier, device, dataloaders[TRAIN], len(image_datasets[TRAIN]), True, 0)

# Training Loop
def log_sum_exp(x, axis = 1):
    m = torch.max(x, dim = 1)[0]
    return m + torch.log(torch.sum(torch.exp(x - m.unsqueeze(1)), dim = axis))

# Lists to keep track of progress
img_list = []
G_losses = []
D_losses = []
iters = 0

validation_losses = []
validation_accuracies = []

train_losses = []
train_accuracies = []

best_model_wts = copy.deepcopy(classifier.state_dict())
best_acc = 0.0

print("Starting Training Loop...")
# For each epoch
for epoch in range(num_epochs):
    # For each batch in the dataloader
    # for i, batch in enumerate(dataloaders[TRAIN], 0):
    for batch_number, (images, labels) in enumerate(dataloaders[TRAIN]):
        # TRAIN THE DISCRIMINATOR (THE CLASSIFIER)
        classifier.train()
        optimizerC.zero_grad()

        # 1. on Unlabelled data
        data = images.type('torch.FloatTensor').to(device)        
        outputs = classifier(data)
        logz_unlabel = log_sum_exp(outputs)
        lossUL = 0.5 * (-torch.mean(logz_unlabel) + torch.mean(F.softplus(logz_unlabel)))
        lossUL.backward()

        # 2. on the generated data
        noise = torch.randn(batch_size, 100, 1, 1, device=device)
        generated = (netG(noise)+1.0)/2.0
        outputs = classifier(generated.detach()) # detach() because we are not training G here
        logz_fake = log_sum_exp(outputs)
        lossD = 0.5*torch.mean(F.softplus(logz_fake))
        lossD.backward()

        # 3. on labeled data
        output = classifier(labeled_data)
        logz_label = log_sum_exp(output)
        prob_label = torch.gather(output, 1, labeled_classes.unsqueeze(1))
        labeled_loss = -torch.mean(prob_label) + torch.mean(logz_label)
        labeled_loss.backward()

        optimizerC.step()
        
        # TRAIN THE GENERATOR
        netG.train()
        optimizerG.zero_grad()
        
        outputs = classifier(generated)
        logz_unlabel = log_sum_exp(outputs)
        lossG = 0.5 * (-torch.mean(logz_unlabel) + torch.mean(F.softplus(logz_unlabel)))
        lossG.backward()
        optimizerG.step() 

    generated = (netG(fixed_noise)+1.0)/2.0
    vutils.save_image(generated.cpu().detach(), ('generated_%d.jpg' % epoch), normalize=True)
    
    train_loss, train_accuracy = test(classifier, device, dataloaders[TRAIN], len(image_datasets[TRAIN]), True, 0)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    validation_loss, validation_accuracy = test(classifier, device, dataloaders[VAL], len(image_datasets[VAL]), True, 1)
    validation_losses.append(validation_loss)
    validation_accuracies.append(validation_accuracy)
        
    if validation_accuracy > best_acc:
        best_acc = validation_accuracy
        best_classifier_wts = copy.deepcopy(classifier.state_dict())

print('Best VAL validation accuracy: ', np.max(np.array(validation_accuracies)),
      '% after ', np.argmax(np.array(validation_accuracies)), ' training epochs')

# load best model weights
classifier.load_state_dict(best_classifier_wts)

print("\nBest model on the testing set: ")
test(classifier, device, dataloaders[TEST], len(image_datasets[TEST]), True, 2)

plt.xlabel("epoch")
plt.ylabel("loss")
plt.plot(range(len(train_losses)), np.array(train_losses), label="train")
plt.plot(range(len(validation_losses)), np.array(validation_losses), label="validation")
plt.legend()
plt.show()

plt.xlabel("epoch")
plt.ylabel("accuracy")
plt.plot(range(len(train_accuracies)), np.array(train_accuracies), label="train")
plt.plot(range(len(validation_accuracies)), np.array(validation_accuracies), label="validation")
plt.legend()
plt.show()

print('Best VAL validation accuracy: ', np.max(np.array(validation_accuracies)),
      '% after ', np.argmax(np.array(validation_accuracies)), ' training epochs')

# load best model weights
classifier.load_state_dict(best_classifier_wts)

print("\nBest model on the testing set: ")
test(classifier, device, dataloaders[TEST], len(image_datasets[TEST]), True, 2)